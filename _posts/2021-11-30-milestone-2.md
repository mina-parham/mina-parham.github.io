---
layout: post
title: Hockey Goal Predictions
author: Jizhou Wang, Abhay Puri, Binulal Narayanan, Qilin Wang
#   Jizhou:
#     name: Jizhou Wang
#     url: https://github.com/jawing/
#     email: jizhou.wang@mila.quebec
#   Abhay:
#     name: Abhay Puri
#     url: https://github.com/abhaypuri
#     email: abhaypuri98@gmail.com
#   Binulal:
#     name: Binulal Narayanan
#     url: https://github.com/mobicus
#     email: binulal.narayanan@umontreal.ca
#   Qilin:
#     name: Qilin Wang
#     url: https://github.com/QilinWang
#     email: qilin@fastmail.com
tags: Hockey Goal Predictions
---

## Presented by [this notebook](https://github.com/Jawing/ift6758-project-template-main/blob/main/milestone2.ipynb)

In the [previous post](/2021/10/15/milestone-1.html) we showed how to obtain, tidy and visualize NHL games data. Now, let us experiment with the data to predict goals.

## Experiment Tracking

The experiments described in this blog are logged to [this](https://www.comet.ml/binulal/milestone-2) **[comet.ml](https://www.comet.ml/)** workspace.

## Feature Engineering Part 1 & Visualizations

For feature engineering, we have visualized the data to get an intuition of outliers, biases that could be present for feature selection/imputation later on.

### A histogram of shot counts (goals and no-goals separated), binned by *angle*

Although teams like to shoot around -30, 0 (meaning shooting directly in front of the net) and 30 degrees, the goals are distributed as bell-curve shape with 0 degree shots having the highest probability to score.

<img src = "/assets/images/milestone2/m2_q2_1_angle_to_goal.png">

### A histogram of shot counts (goals and no-goals separated), binned by *distance*

Scoring is harder when the shot distance is larger than 25 feet, yet teams shots are quite evenly distributed across different distances.
Shots are rare past 70 feet, which makes sense as it is shot from the defensive zone.

<img src = "/assets/images/milestone2/m2_q2_1_dist_to_goal.png">

### A 2D histogram where one axis is the distance and the other is the angle. You do not need to separate goals and no-goals

It seems that shots have a very hard time turning into goals when shot angles are larger than 50 or when distance larger than 40.

<img src = "/assets/images/milestone2/m2_q2_1_joint_ang_to_dist_kde.png">

### A histogram of shot distance/shot angle vs goal ratio

The goal ratio is highest within 20 feet, lower when between 20-40 feet and much lower outside of 40 feet. It seems that as shot distance increase past 100 feet, the goal ratio starts to increase again. It suggest that, although the number of shots taken at a higher distance is low, the opportunity of scoring when taking a long shot is high. This makes sense especially when there is an empty net.

<img src = "/assets/images/milestone2/m2_q2_2_shot_dist_goal_ratio.png">

The goal ratio to shot angle seems to have a bell-shape curve around zero from 90 to -90 degrees. Although interestingly the goal ratio increases dramatically from -90 to -180 degrees. After looking at the data and verifying with some video examples ([Sharp Angle Shot footage](https://www.nhl.com/video/armia-scores-from-sharp-angle/t-300137966/c-67423703)), it suggest that, although the number of shots taken at this angle is low, the opportunity of scoring when taken can be high.

<img src = "/assets/images/milestone2/m2_q2_2_shot_angle_goal_ratio.png">

### A histogram of goal, binned by distance (separated empty net and non-empty net events)

<img src = "/assets/images/milestone2/m2_q2_3_dist_to_emptynet.png">

An examples of wrong information (rinkSide):

Given gameID: 2018020953 and eventidx: 368 with [Jakub Voracek's goal](https://www.nhl.com/video/voraceks-late-game-tying-goal/t-300064528/c-66170503), we have found that data was wrongly recorded with a much larger shot distance while scoring on a non-empty net shown [here](https://www.nhl.com/gamecenter/pit-vs-phi/2019/02/23/2018020953#game=2018020953,game_state=final,game_tab=plays).  

## Baseline Models

For our baseline, we used a logistic regression model with only a single *distance to goal* metric. After fitting to the shot data, it has achieved an **accuracy** of **0.91** and an **AUC** score of **0.69**. However, the model pushes all its predictions towards non-goal situations, which means that it will predict all outcome to be a non-goal. Therefore, it has a zero score on precision, recall and f1-score for shots that are goals. This is a sign of overfitting because we want our model to predict situations that would result in a goal as well.

All simple features tested on the logistic regression model:

- Distance only
- Angles only
- Distance & Angles
- Random only

### Summary of all four models plotted

#### Goal Rate

<img src = "/assets/images/milestone2/q35_Merging_GR.png">

The goal rate curves of different models.
The logistic regression with angle only plot seems to be predicting a constant goal rate at every shot percentile, which does not seem to be reliable when determining goals.  

#### Cumulative Curves

<img src = "/assets/images/milestone2/q35_Merging_CP.png">

#### ROC Curves

<img src = "/assets/images/milestone2/q35_Merging_ROC.png">

The ROC curves show that logistic regression with both distance and angle (or with just the angle) as features produce the best results. Logistic regression with only angle as feature produces a result not much better than a random guess.  

#### Calibration Curves

<img src = "/assets/images/milestone2/q35_Merging_calibration.png">

For the calibration curves, we can also see that logistic regression with angle and distance produces some improvement, but its probabilistic predictions hardly fits a perfectly calibrated binary classifier.

### Links to the experiment entries above in comet.ml

[Logistic Regression, trained on distance](https://www.comet.ml/binulal/milestone-2/4d23e3c07b2c4130a7f6dbb50b5eb1e7)  
[Logistic Regression, trained on angle only](https://www.comet.ml/binulal/milestone-2/d909638434b943e79be423d292ec5378)  
[Logistic regression , trained on both](https://www.comet.ml/binulal/milestone-2/57eb37f26f374217a1bf19e460ff0ce9)  

## Feature Engineering Part 2

This time we have added many novel features from the shot data to improve our model prediction.

**Feature list Description** (before preprocessing)

- Game_id : Id for the hockey game.
- Event_idx: Id for an event (shot or goal) in the game.
- Speed: (distance from the previous event)/(time since previous event seconds).
- periodSeconds_last: Time from the last event (seconds).
- eventType_last: Last event type.
- Rebound: True only if the last event was also a shot.
- Period: Period in the hockey game.
- periodType: Type of period in the game. ('REGULAR','OVERTIME','SHOOTOUT')
- periodTime: Min:sec, Time during the period.
- periodSeconds: PeriodTime converted to seconds.
- teamInfo: Name of team who made the shot.
- isGoal: True only if shot is goal.
- shotType: Different shot types.
- Coordinates_x: X coordinate where the event happened.
- Coordinates_y: Y coordinate where the event happened.
- Coordinates_x_last: X coordinate where the last event happened.
- Coordinates_y_last: Y coordinate where the last event happened.
- Distance_last: Distance between current and last event.
- Dist_goal: Distance between event and goal.
- Angle_goal: Angle [-180,180] between the shot event and goal.
- Angle_change: Only when the shot is a rebound, the change in angle between shots.
- Angle_speed: Angle_change/(time between current and last shot)
- Shooter: Name of the shooter.
- Goalie: Name of the goalie.
- emptyNet: True if a shot is taken on an empty Net.
- Strength: Strength of team on the playing field.
- homeTeam: Name of home team.
- awayTeam: Name of away team.
- homeSide: Left if home starts in period 1 on the left side, right otherwise.

The dataframe can be found in this [link](https://www.comet.ml/binulal/milestone-2/b95f15e394374ac0b4509d170efe357d?assetId=995878f6b20d469d8fc8d2eb65ebd2f8&assetPath=dataframes&experiment-tab=assets).

## Advanced Models

Using all the newly added features, we made sure to preprocess the data into a numerical form.

- Redundant columns are dropped such as ‘game_id’, ‘event_idx’, ‘periodTime’.
- All columns with more than 60% NAN values are dropped.
- All rows with NAN values are dropped.
- ‘isGoal’, ‘rebound’, ‘emptyNet’, ‘homeSide’ columns are binarized into 0, 1.
- One hot encoding is applied to the columns ‘periodType’, ‘eventType_last’, ‘teamInfo’, ‘shotType’, ‘homeTeam’, ‘awayTeam’.
- ‘shooter’ and ‘goalie’ columns are dropped because of the low data variance. The total number of features ended up being 128.

After preprocessing, the data was **stratified-split** into train and validation sets. **Grid Search CV** was used to search for the most optimal model parameter during training and validation.

### XGBoost Model

| ![alt](/assets/images/milestone2/q52_XGboost_CP.png) | ![alt](/assets/images/milestone2/q52_XGboost_GR.png) |
| ![alt](/assets/images/milestone2/q52_Xgboost_ROC.png) | ![alt](/assets/images/milestone2/q52_XGboost_RD.png) |

The ROC curve has AUC value of 0.76 and the calibration is much smoother compared to before, and it is almost perfectly calibrated in for mean probabilities less than 0.6. For probabilities larger than 0.6, suggesting hyperparameter search and additional features has improved the prediction in a significant manner.

[Link to the model](https://www.comet.ml/binulal/milestone-2/8d75cbfc7cf9446f90560acf7c51ea53)

### Feature selection on XGBoost

We have used various feature selection methods such as correlation matrix, XGboost feature importance weight, chi square method and SHAP value.

The selected features are the top 10 most important according to the picture listed below:

<img src="/assets/images/milestone2/q53_feature_1.png">

For reference, the correlation matrix is also included:

<img src="/assets/images/milestone2/q53_heat.png">

The SHAP value importance are as follows:

<img src="/assets/images/milestone2/q53_shap1.png">

#### XGBoost Model with top 10 selected features

| ![alt](/assets/images/milestone2/q53_Xgboost_ROC.png) | ![alt](/assets/images/milestone2/q53_XGboost_tuned_CP.png) |
| ![alt](/assets/images/milestone2/q53_XGboost_tuned_GR.png) | ![alt](/assets/images/milestone2/q53_XGboost_tuned_RD.png) |

The AUC value is 0.76, which shows no deterioration from the full model, which suggests that our predictive power of the slimmed down model is as good as the full model.

[Link to the model](https://www.comet.ml/binulal/milestone-2/2e98573c75804e6998136ba84d928b79)

## More Advanced Models

For the **logistic regression model**, a **Grid Search CV** strategy was used to select the *C* parameter and the *number of components* after fitting the data with PCA. The data is first standardized in the pipeline, then PCA is applied then finally the logistic regression model. The resulting *best* parameters were PCA_n=90, C=10000.

Below are the plots for the logistic regression model.

| ![alt](/assets/images/milestone2/q61_logR_GR.png) | ![alt](/assets/images/milestone2/q61_logR_CP.png) |
| ![alt](/assets/images/milestone2/q61_logR_ROC.png) | ![alt](/assets/images/milestone2/q61_logR_RD.png) |

For the **svc model**, a **Grid Search CV** strategy was used to select the *C, kernel* parameters. The data is first standardized in the pipeline, then PCA (with number of components = 85) is applied then finally the svc model. The resulting best parameters were C=10, kernel=’rbf’.

![alt](/assets/images/milestone2/q62_svc_ROC.png)

For the **random forest model**, The data is directly applied to the random forest model with the default parameters. The random forest model has an **AUC of 0.76**, highest among all models.

| ![alt](/assets/images/milestone2/q63_rf_GR.png) | ![alt](/assets/images/milestone2/q63_rf_CP.png) |
| ![alt](/assets/images/milestone2/q63_rf_ROC.png) | ![alt](/assets/images/milestone2/q63_rf_RD.png) |

For the **adaboost model**, a **Grid Search CV** strategy was used to select the *n_estimators*, *learning_rate* parameters. The data is directly applied to the adaboost model. The *resulting* best parameters were n_estimators=10, learning_rate=0.01. The adaboost model has an **AUC of 0.68**.

Below are the plots for the adaboost model.

| ![alt](/assets/images/milestone2/q64_ada_GR.png) | ![alt](/assets/images/milestone2/q64_ada_CP.png) |
| ![alt](/assets/images/milestone2/q64_ada_ROC.png) | ![alt](/assets/images/milestone2/q64_ada_RD.png) |

For the **mlp model**, a **Grid Search CV** strategy was used to select the *hidden_layer_sizes*. The data is first standardized in the pipeline, then PCA is applied then finally the mlp model. The resulting best parameters were C=10, kernel=’rbf’, hidden_layer_sizes = (100,100).

The MLP model seems to have a smooth curve on the shot prob model percentile plots. It has an **AUC of 0.74**

Below are the plots for the adaboost model.

| ![alt](/assets/images/milestone2/q65_mlp_GR.png) | ![alt](/assets/images/milestone2/q65_mlp_CP.png) |
| ![alt](/assets/images/milestone2/q65_mlp_ROC.png) | ![alt](/assets/images/milestone2/q65_mlp_RD.png) |

Finally For the **voting ensemble model**, we have included the previous random forest, mlp, logistic regression and adaboost models with *equal* weights. The data is fitted with *soft voting*. The final model used on the test set was the ensemble model in hopes for a better generalization performance. It has an **AUC of 0.76** as good as the random forest model.

Below are the plots for the voting ensemble model.

| ![alt](/assets/images/milestone2/q66_ens_GR.png) | ![alt](/assets/images/milestone2/q66_ens_CP.png) |
| ![alt](/assets/images/milestone2/q66_ens_ROC.png) | ![alt](/assets/images/milestone2/q66_ens_RD.png) |

The **precision** metric for most of the models are *close to 1, other than svc (0.6)*. The **f1 score** is *around 0.09* for most of the models, other than svc (0.12). The **recall score** is around *0.05* for most of the models, other than svc (0.067). These scores seem to be a lot lower because of the false negatives. It seems to be difficult for the models to learn which shots lead to a goal.

Experiment links on comet.ml for each of the models described above.

- [Logistic Regression](https://www.comet.ml/binulal/milestone-2/dfed4cec3eb74e8282128c6b6f1d6beb)
- [SVC](https://www.comet.ml/binulal/milestone-2/88d76b3e5bb046768dda45bbcf2b5fab)
- [Random Forrest](https://www.comet.ml/binulal/milestone-2/e2bec5ea1f8e458bb3d12c9c31536ced)  
- [Adaboost](https://www.comet.ml/binulal/milestone-2/a4b50b1c75e94d2eb2d2fa53406b2040)
- [MLP](https://www.comet.ml/binulal/milestone-2/87bd90b3aad74d48b1ec1da8374a4508)
- [Ensemble](https://www.comet.ml/binulal/milestone-2/30164fae30564a85ae8dd1d0afe43dd7)

## Evaluating on test set

For models tested on the regular season test set, the results are the following:

| ![alt](/assets/images/milestone2/q7_calibration_Regular_test.png) | ![alt](/assets/images/milestone2/q7_cumulative_Regular_test.png) |
| ![alt](/assets/images/milestone2/q7_ROC_Regular_test.png) | ![alt](/assets/images/milestone2/q7_goalrate_Regular_test.png) |

The voting [ensemble model](https://www.comet.ml/binulal/milestone-2/49e4d10bdb9b47ec99aef56ab5586c34) and the XGboost model had similar performance on the test set from the regular seasons as on the validation set. It performed slightly better on the test set for regular seasons. The **AUC score** of the ensemble and XGboost models are **0.76** and **0.77** respectively , on par with our result on the training data. This shows that the models gives a satisfactory result in terms of generalization.

For models tested on the playoffs season test set, the results are the following:

| ![alt](/assets/images/milestone2/q7_calibration_Playoff_test.png) | ![alt](/assets/images/milestone2/q7_cumulative_Playoff_test.png) |
| ![alt](/assets/images/milestone2/q7_ROC_Playoff_test.png) | ![alt](/assets/images/milestone2/q7_goalrate_Playoff_test.png) |

In conclusion, the voting [ensemble model](https://www.comet.ml/binulal/milestone-2/d38380c1fd564ed78806e14674d74282)
seems to generalize well as its performance on the test set from the playoffs data is comparably the same as on the validation set from the regular season data. The **AUC score** of the ensemble method is **0.70**, which is a slight drop compared to our regular season prediction. It is still a satisfactory performance. However The fined tuned XGboost model had a better ROC curve with an **AUC score of 0.74** which seems to do a better job compared to the ensemble model at ‘generalization’ performance.

[Prev: Hockey Goal Visualizations](/2021/10/15/milestone-1.html)  
